[
  {
    "position": "Software Engineer",
    "company": "Microsoft",
    "location": "Bengaluru, Karnataka, India",
    "date": "2025-07-14",
    "salary": "Not specified",
    "jobUrl": "https://in.linkedin.com/jobs/view/software-engineer-at-microsoft-4266587982?position=1&pageNum=0&refId=BYLSx0BZGtZh2eH4pz2Fdg%3D%3D&trackingId=sm%2FoSklyVBTG7a2IWK946g%3D%3D",
    "companyLogo": "https://media.licdn.com/dms/image/v2/D560BAQH32RJQCl3dDQ/company-logo_100_100/B56ZYQ0mrGGoAU-/0/1744038948046/microsoft_logo?e=2147483647&v=beta&t=rr_7_bFRKp6umQxIHErPOZHtR8dMPIYeTjlKFdotJBY",
    "agoTime": "4 days ago",
    "metadata": {
      "keyword": "AI Accelerator Engineer",
      "location": "Bangalore",
      "experienceLevel": "Chief Technology Officer",
      "remoteFilter": "hybrid"
    },
    "job_description": "Microsoft Azure Storage is a highly distributed, massively scalable, and ubiquitously accessible cloud storage platform. Azure storage already runs at Exascale (storing Exabytes of data) and we will scale our designs over the next decade to support Zettascale (storing Zettabytes of data). Within Azure Storage, the xDPU team is focused in bringing up the storage stack on DPU (Data Processing Units) based nodes to provide unmatched performance at lowest cost. We are hiring experienced engineers to join us in the mission of developing and deploying DPU based storage.As a Software Engineer in Azure Storage, you will help build performant scale out block storage on Data Processing Units (DPU) hardware. You will be involved in all phases of the storage lifecycle, design, implementation, test, deployment and support. This opportunity will allow you to learn about cloud computing as well as building and supporting cloud services at scale.Microsoft\u2019s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.ResponsibilitiesWorks with appropriate stakeholders (e.g., project lead) to determine requirements for a set of features. Begins to leverage a variety of feedback channels to incorporate insights into future designs or solution fixes.Creates and implements code for a product, service, or feature, reusing code as applicable. Writes and learns to create code that is extensible and maintainable. Considers diagnosability, reliability, and maintainability with few defects, and understands when the code is ready to be shared and delivered.Contributes to processes for the architecture of a product/solution feature and helps to create proposals for architecture by testing design hypotheses and helping to refine code plans, with technical leadership from others.Works in a culture of continuous improvement, adaptation, reflection and growthQualificationsRequired/Minimum Qualifications:Bachelor's Degree in Computer Science, or related technical discipline with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or PythonOR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings:\u202f Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud Background Check upon hire/transfer and every two years thereafter. Additional Or Preferred QualificationsBachelor's Degree in Computer ScienceOR related technical field AND 1+ year(s) technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript,OR PythonOR Master's Degree in Computer Science or related technical field with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or PythonOR equivalent experience.1+ year(s) experience of distributed systems and storage1+ year(s) experience of machine learning techniques with a solid understanding of model training, evaluation, and deployment. Familiarity with cloud-based ML tools and a passion for building responsible AI solutions that solve real-world problems.#azurecorejobsMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",
    "job_type": "Not specified",
    "remote_status": "Not specified",
    "experience_level": "1+ year(s) technical engineering experience",
    "required_skills": [
      "C",
      "C++",
      "C#",
      "Java",
      "JavaScript",
      "Python",
      "distributed systems",
      "storage",
      "machine learning techniques",
      "design",
      "implementation",
      "test",
      "deployment",
      "support",
      "architecture"
    ],
    "education": "Bachelor's Degree in Computer Science, or related technical discipline OR Master's Degree in Computer Science or related technical field",
    "technologies": [
      "C",
      "C++",
      "C#",
      "Java",
      "JavaScript",
      "Python",
      "DPU"
    ],
    "job_responsibilities": "Build performant scale out block storage on Data Processing Units (DPU) hardware; involved in all phases of the storage lifecycle including design, implementation, test, deployment and support; determine requirements for features; create and implement code; contribute to architecture processes."
  },
  {
    "position": "AI/ML Engineer",
    "company": "Apexon",
    "location": "Bangalore Urban, Karnataka, India",
    "date": "2025-07-16",
    "salary": "Not specified",
    "jobUrl": "https://in.linkedin.com/jobs/view/ai-ml-engineer-at-apexon-4267674001?position=2&pageNum=0&refId=BYLSx0BZGtZh2eH4pz2Fdg%3D%3D&trackingId=jwMmwBe2ra7vnx4tIhQ1Pg%3D%3D",
    "companyLogo": "https://media.licdn.com/dms/image/v2/C560BAQHehBd-C9n-AQ/company-logo_100_100/company-logo_100_100/0/1658434447598/apexon_logo?e=2147483647&v=beta&t=rY-hbkwT2d1CSCTFW1NLLiJNqcZm44piZJ9b3ZmXLvw",
    "agoTime": "3 days ago",
    "metadata": {
      "keyword": "AI Accelerator Engineer",
      "location": "Bangalore",
      "experienceLevel": "Chief Technology Officer",
      "remoteFilter": "hybrid"
    },
    "job_description": "About Apexon:Apexon is a digital-first technology services firm specializing in accelerating business transformation and delivering human-centric digital experiences. We have been meeting customers wherever they are in the digital lifecycle and helping them outperform their competition through speed and innovation. Apexon brings together distinct core competencies \u2013 in AI, analytics, app development, cloud, commerce, CX, data, DevOps, IoT, mobile, quality engineering and UX, and our deep expertise in BFSI, healthcare, and life sciences \u2013 to help businesses capitalize on the unlimited opportunities digital offers. Our reputation is built on a comprehensive suite of engineering services, a dedication to solving clients\u2019 toughest technology problems, and a commitment to continuous improvement. Backed by Goldman Sachs Asset Management and Everstone Capital, Apexon now has a global presence of 15 offices (and 10 delivery centers) across four continents.We enable #HumanFirstDigitalKey Responsibilities:Design, develop, and maintain CI/CD pipelines for ML models and data workflows.Collaborate with data science teams to productionize models using tools like MLflow, Kubeflow, or SageMaker.Automate training, validation, testing, and deployment of machine learning models.Monitor model performance, drift, and retraining needs.Ensure version control of datasets, code, and model artifacts.Implement model governance, audit trails, and reproducibility.Optimize model serving infrastructure (REST APIs, batch/streaming inference).Integrate ML solutions with cloud services (AWS, Azure, GCP).Ensure security, compliance, and reliability of ML systems.Required Skills and Qualifications:Bachelor\u2019s or master\u2019s degree in computer science, Engineering, Data Science, or related field.5+ years of experience in MLOps, DevOps, or ML engineering roles.Strong experience with ML pipeline tools (MLflow, Kubeflow, TFX, SageMaker Pipelines).Proficiency in containerization and orchestration tools (Docker, Kubernetes, Airflow).Strong Python coding skills and familiarity with ML libraries (scikit-learn, TensorFlow, PyTorch).Experience with cloud platforms (AWS, Azure, GCP) and their ML services.Knowledge of CI/CD tools (GitLab CI/CD, Jenkins, GitHub Actions).Familiarity with monitoring/logging tools (Prometheus, Grafana, ELK, Sentry).Understanding of data versioning (DVC, LakeFS) and feature stores (Feast, Tecton).Strong grasp of model testing, validation, and monitoring in production environments.Our Commitment to Diversity & Inclusion:Did you know that Apexon has been Certified\u2122 by Great Place To Work\u00ae, the global authority on workplace culture, in each of the three regions in which it operates: USA (for the fourth time in 2023), India (seven consecutive certifications as of 2023), and the UK.Apexon is committed to being an equal opportunity employer and promoting diversity in the workplace. We take affirmative action to ensure equal employment opportunity for all qualified individuals. Apexon strictly prohibits discrimination and harassment of any kind and provides equal employment opportunities to employees and applicants without regard to gender, race, color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. You can read about our Job Applicant Privacy policy here Job Applicant Privacy Policy (apexon.com)Our Perks and Benefits:Our benefits and rewards program has been thoughtfully designed to recognize your skills and contributions, elevate your learning/upskilling experience and provide care and support for you and your loved ones. As an Apexon Associate, you get continuous skill-based development, opportunities for career advancement, and access to comprehensive health and well-being benefits and assistance.We also offer:o Group Health Insurance covering family of 4o Term Insurance and Accident Insuranceo Paid Holidays & Earned Leaveso Paid Parental LeaveoLearning & Career Developmento Employee Wellness",
    "job_type": "Not specified",
    "remote_status": "Not specified",
    "experience_level": "5+ years",
    "required_skills": [
      "MLflow",
      "Kubeflow",
      "TFX",
      "SageMaker Pipelines",
      "Docker",
      "Kubernetes",
      "Airflow",
      "Python",
      "scikit-learn",
      "TensorFlow",
      "PyTorch",
      "AWS",
      "Azure",
      "GCP",
      "GitLab CI/CD",
      "Jenkins",
      "GitHub Actions",
      "Prometheus",
      "Grafana",
      "ELK",
      "Sentry",
      "DVC",
      "LakeFS",
      "Feast",
      "Tecton",
      "REST APIs"
    ],
    "education": "Bachelor\u2019s or master\u2019s degree in computer science, Engineering, Data Science, or related field",
    "technologies": [
      "MLflow",
      "Kubeflow",
      "TFX",
      "SageMaker Pipelines",
      "Docker",
      "Kubernetes",
      "Airflow",
      "Python",
      "scikit-learn",
      "TensorFlow",
      "PyTorch",
      "AWS",
      "Azure",
      "GCP",
      "GitLab CI/CD",
      "Jenkins",
      "GitHub Actions",
      "Prometheus",
      "Grafana",
      "ELK",
      "Sentry",
      "DVC",
      "LakeFS",
      "Feast",
      "Tecton",
      "REST APIs"
    ],
    "job_responsibilities": "Design, develop, and maintain CI/CD pipelines for ML models and data workflows. Collaborate with data science teams to productionize models using tools like MLflow, Kubeflow, or SageMaker. Automate training, validation, testing, and deployment of machine learning models. Monitor model performance, drift, and retraining needs. Ensure version control of datasets, code, and model artifacts. Implement model governance, audit trails, and reproducibility. Optimize model serving infrastructure (REST APIs, batch/streaming inference). Integrate ML solutions with cloud services (AWS, Azure, GCP). Ensure security, compliance, and reliability of ML systems."
  },
  {
    "position": "Software Engineer, ML Systems",
    "company": "eBay",
    "location": "Bengaluru, Karnataka, India",
    "date": "2025-07-18",
    "salary": "Not specified",
    "jobUrl": "https://in.linkedin.com/jobs/view/software-engineer-ml-systems-at-ebay-4267435259?position=3&pageNum=0&refId=BYLSx0BZGtZh2eH4pz2Fdg%3D%3D&trackingId=11f3G%2FydYaC5zNenb9DYWQ%3D%3D",
    "companyLogo": "https://media.licdn.com/dms/image/v2/C560BAQFfGj-Xuawo6A/company-logo_100_100/company-logo_100_100/0/1634568184469/ebay_logo?e=2147483647&v=beta&t=BEp-EQMNBexZVYGMcq6jeof_bX8QzuCCq4BEG6UCRdM",
    "agoTime": "1 day ago",
    "metadata": {
      "keyword": "AI Accelerator Engineer",
      "location": "Bangalore",
      "experienceLevel": "Chief Technology Officer",
      "remoteFilter": "hybrid"
    },
    "job_description": "At eBay, we're more than a global ecommerce leader \u2014 we\u2019re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We\u2019re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.Our customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work \u2014 every day. We're in this together, sustaining the future of our customers, our company, and our planet.Join a team of passionate thinkers, innovators, and dreamers \u2014 and help us connect people and build communities to create economic opportunity for all.Looking for a company that inspires passion, courage and creativity, where you can be on the team shaping the future of global commerce? Want to shape how millions of people buy, sell, connect, and share around the world? If you\u2019re interested in joining a purpose driven community that is dedicated to crafting an ambitious and inclusive work environment, join eBay \u2013 a company you can be proud to be with.Our Recommendations team works on delivering recommendations at scale and in near real time to our buyers on our website and native app platforms. Recommendations are a core part of how our buyers navigate eBay\u2019s vast and varied inventory. Our team develops state-of-the-art recommendations systems, including deep learning based retrieval systems for personalized recommendations, machine learned ranking models, GenAI/LLM powered recommendations, as well as advanced MLOps in a high volume traffic industrial e-commerce setting.We are building cutting edge recommender systems powered by the latest ML, NLP, LLM/GenAI/RAG and AI technologies. Additionally, we are building production integrations with Google GCP Vertex AI platforms to supercharge our item recommendation algorithms. Come join our innovative engineering and applied research team!This Is An Opportunity ToInfluence how people will interact with eBay\u2019s recommender systems in the future, and how recommender systems technology will evolveWork with unique and large data sets of unstructured multimodal data representing eBay's vast and varied inventory, including billions of items and millions of usersDevelop and deploy state-of-the-art AI models to production which have direct measurable impact on eBay buyersDeploy big data technology and large scale data pipelinesDrive marketplace GMB as well as advertising revenue via organic and sponsored recommendationsQualificationsMS in Computer Science or related area with 3 years of relevant work experience (or BS/BA with 5 years) in Engineering / Machine Learning / AIExperience building large scale distributed applications and expertise in any OO language (Scala, Java, etc.) Experience building with no sql databases and key value stores (MongoDB, Redis, etc)Generalist with a can do attitude and willingness to learn/pick up new skill sets as neededExperience with big data pipelines (Hadoop, Spark) is a plus Experience in AI applied research and industrial recommendation systems is a plusExperience with Large Language Models (LLMs) and prompt engineering is a plusLinks To Some Of Our Previous WorkTech Blog 2025 (Multimodal GenAI)Tech Blog 2025 (GenAI Agentic Platform)RecSys 2024 Workshop paperGoogle Cloud Blog 2024eBay Tech Blog 2023eBay Tech Blog 2022RecSys 2021 paperPlease see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.",
    "job_type": "Not specified",
    "remote_status": "Not specified",
    "experience_level": "3 years of relevant work experience (or BS/BA with 5 years)",
    "required_skills": [
      "Scala",
      "Java",
      "NoSQL databases",
      "Key-value stores",
      "MongoDB",
      "Redis",
      "Hadoop",
      "Spark",
      "AI applied research",
      "Industrial recommendation systems",
      "Large Language Models (LLMs)",
      "Prompt engineering",
      "Deep learning",
      "Machine learning",
      "MLOps",
      "Natural Language Processing (NLP)",
      "Generative AI (GenAI)",
      "Retrieval Augmented Generation (RAG)",
      "Google GCP Vertex AI"
    ],
    "education": "MS in Computer Science or related area (or BS/BA)",
    "technologies": [
      "Scala",
      "Java",
      "NoSQL databases",
      "Key-value stores",
      "MongoDB",
      "Redis",
      "Hadoop",
      "Spark",
      "Large Language Models (LLMs)",
      "Prompt engineering",
      "Deep learning",
      "Machine learning",
      "MLOps",
      "Natural Language Processing (NLP)",
      "Generative AI (GenAI)",
      "Retrieval Augmented Generation (RAG)",
      "Google GCP Vertex AI"
    ],
    "job_responsibilities": "Deliver recommendations at scale and in near real time; develop state-of-the-art recommendations systems (including deep learning, machine learned ranking, GenAI/LLM powered, and advanced MLOps); build cutting edge recommender systems powered by ML, NLP, LLM/GenAI/RAG and AI technologies; build production integrations with Google GCP Vertex AI platforms; influence recommender systems evolution; work with large unstructured multimodal data sets; develop and deploy state-of-the-art AI models to production; deploy big data technology and large scale data pipelines; drive marketplace GMB and advertising revenue via recommendations."
  },
  {
    "position": "Junior Data Scientist",
    "company": "Cardinal Health",
    "location": "Bangalore",
    "date": "2025-07-17",
    "salary": "Not specified",
    "jobUrl": "https://in.linkedin.com/jobs/view/junior-data-scientist-at-cardinal-health-4268216056?position=4&pageNum=0&refId=BYLSx0BZGtZh2eH4pz2Fdg%3D%3D&trackingId=3cOr3jPCsds%2BEg2F32%2Fe0A%3D%3D",
    "companyLogo": "https://media.licdn.com/dms/image/v2/D4E0BAQHseggiBegb7A/company-logo_100_100/company-logo_100_100/0/1719772831840/cardinal_health_logo?e=2147483647&v=beta&t=tBty3VPZQtB9YLng5ahCYYoofIX2Y3ApRnlDZwAMn0s",
    "agoTime": "2 days ago",
    "metadata": {
      "keyword": "AI Accelerator Engineer",
      "location": "Bangalore",
      "experienceLevel": "Chief Technology Officer",
      "remoteFilter": "hybrid"
    },
    "job_description": "About Us:Headquartered in Dublin, Ohio, Cardinal Health, Inc. (NYSE: CAH) is a distributor of pharmaceuticals, a global manufacturer and distributor of medical and laboratory products, and a provider of performance and data solutions for healthcare facilities.We are a crucial link between the clinical and operational sides of healthcare, delivering end-to-end solutions and data-driving insights that advance healthcare and improve lives every day. With deep partnerships, diverse perspectives and innovative digital solutions, we build connections across the continuum of care.With more than 50 years of experience, we seize the opportunity to address healthcare's most complicated challenges \u2014 now, and in the future.With approximately 48,000 employees across several countries and Fiscal 2023 revenues of $205 billion, Cardinal Health ranks among the top 15 on the Fortune 500.In Bangalore we have created an Innovation and Global Capability Centre (GCC) in 2021 as part of our Global Business Services (GBS) operating model that allows us to in-house talent and scale that talent across our business in areas such as Enterprise IT, Commercial Technologies and Business Process Solutions. Our ambition is to build differentiated opportunities that allows our organization to advance rapidly to be healthcare\u2019s most trusted partner.What Data Science contributes to Cardinal Health The Data & Analytics Function oversees the analytics lifecycle in order to identify, analyze and present relevant insights that drive business decisions and anticipate opportunities to achieve a competitive advantage. This function manages analytic data platforms, the access, design and implementation of reporting/business intelligence solutions, and the application of advanced quantitative modeling. Data Science applies base, scientific methodologies from various disciplines, techniques and tools that extract knowledge and insight from data to solve complex business problems on large data sets, integrating multiple systems. Qualifications2-4 years of experience, preferredBachelor's degree in related field, or equivalent work experience, preferredTechnical support and enhancements for GenAI pipelines with RAGAssist with prompt engineering to improve performanceMonitor system performance, logs, retrieval quality and prompt-effectivenessProvide on-call support during incidentsWhat is expected of you and others at this levelApplies working knowledge in the application of concepts, principles and technical capabilities to perform varied tasksWorks on projects of moderate scope and complexityIdentifies possible solutions to a variety of technical problems and takes action to resolve.Apply judgment within defined parametersReceives general guidance and may receive more detailed instruction on new projectsWork reviewed for sound reasoning and accuracy",
    "job_type": "Not specified",
    "remote_status": "Not specified",
    "experience_level": "2-4 years",
    "required_skills": [
      "GenAI pipelines",
      "RAG",
      "Prompt engineering"
    ],
    "education": "Bachelor's degree in related field, or equivalent work experience",
    "technologies": [
      "GenAI pipelines",
      "RAG",
      "Prompt engineering"
    ],
    "job_responsibilities": "Technical support and enhancements for GenAI pipelines with RAG; Assist with prompt engineering to improve performance; Monitor system performance, logs, retrieval quality and prompt-effectiveness; Provide on-call support during incidents"
  },
  {
    "position": "Data Scientist Executive, Investment Analytics",
    "company": "Jellyfish",
    "location": "Bengaluru, Karnataka, India",
    "date": "2025-07-18",
    "salary": "Not specified",
    "jobUrl": "https://in.linkedin.com/jobs/view/data-scientist-executive-investment-analytics-at-jellyfish-4269521298?position=5&pageNum=0&refId=BYLSx0BZGtZh2eH4pz2Fdg%3D%3D&trackingId=9GOuxofhBVPc8%2BaH5ySMrA%3D%3D",
    "companyLogo": "https://media.licdn.com/dms/image/v2/D4E0BAQGV_2XAUHghUQ/company-logo_100_100/B4EZXSxSv5GYAQ-/0/1742997892462/jellyfishglobal_logo?e=2147483647&v=beta&t=HMuU1aBKugfwJQMUFWyU3A_I-UB51IC-Y_RD5rndTCA",
    "agoTime": "1 day ago",
    "metadata": {
      "keyword": "AI Accelerator Engineer",
      "location": "Bangalore",
      "experienceLevel": "Chief Technology Officer",
      "remoteFilter": "hybrid"
    },
    "job_description": "At Jellyfish, we believe in the power of diverse perspectives and inclusive collaboration. We welcome individuals who excel in collaborative, varied teams and value the unique contributions that each person brings to the table. Jellyfish is a global digital marketing agency; a unique fusion of tech enthusiasts, creative minds, and media and data experts all united to empower our clients along their digital journey. Our commitment to embracing diverse perspectives fuels our innovation and strategies that challenge the status quo, reinvent media activation, and craft influential stories for our global clients and their customers. Join us in shaping a future where business growth and personal fulfilment go hand in hand.Job DescriptionReporting to our Director of Data Science, Investment Analytics, you will create an impact within our Investment Analytics practice and help with the Paid Media data applications that Jellyfish uses to lead expertise, improve, and transform solutions and services for our clients.You'll help lead complex data science solutions, guiding multi-capability presentations, and taking ownership of advanced measurement and testing for our clients. Join us in our mission to deliver data-inspired excellence!Your primary responsibilities will include:Analyze data to discover hidden trends; deliver insights with clear applicable recommendations.You will be working on EST hours (6:30 PM to 3:30 AM IST)Dedicate time to explaining and promoting the use of data science methodologies such as Media Mix Models, Geo-based Incrementally. Experiments, Causal Impact Studies, and other statistically sound testing approaches. Ensure these methodologies enhance campaign performance for existing clients, providing tangible improvements and insights.Develop, and implement Marketing Mix Models to improve media performance, customer experiences, revenue generation, and other outcomes.Work with platform partners to grow the suite of mathematical techniques for Incrementally Testing, Media Mix Modeling and Data Clean Rooms using both open-source and in-house code to create an excellent offering for clients.Document analytics projects in a manner that ensures specific processes can be replicated and scaled across an organisation.QualificationsFluency in English.Programming proficiency in Python and SQL.1 + years of experience in a data role.analyzing media and web data, such as Amazon Marketing Cloud, Google ADH, Campaign Manager, Meta, and Google Analytics .Proficiency in visualizing data using Tableau, Looker, Matplotlib, or equivalents.Strong Experience with the marketing ecosystem and measurement framework, including paid display, search, social, video, organic, web, and app.Skilled in media measurement methodologies such as media mix modeling, incrementality analysis, and attribution modeling.You seek and implement solutions to improve and automate processes.An understanding of machine learning concepts with hands-on experience.A collaborative mindset\u2014you value diverse perspectives, work well in teams, and are motivated by shared goals.Problem-solving skills\u2014when faced with challenges, you work with others to explore options and identify practical solutions. Note: We emphasise skills, expertise and behavioural attributes over years of experience and traditional degrees. If you want to join our collaborative team, we invite you to apply today with your resume in English.Additional Information Join Jellyfish and experience a workplace where we prioritise your growth, celebrate your contributions, and empower you to tailor your work environment to suit your needs.  \ud83d\udcb0 Reward: You'll be eligible to join our discretionary annual bonus scheme.\ud83d\udcab Custom Work Environment: Work remotely in a night shift model.\ud83d\udcc8 Growth, Your Way: Accumulate one paid day each month (2 hours per week) for self-development and access to Jellyfish Learn. Unfortunately, there has been an increase in fake recruiters impersonating Jellyfish and unlawfully using our brand name. If you are unsure if an email with a job offer you have received is genuinely from Jellyfish, or if you suspect any fraudulent activity, please report it to talentacquisition@jellyfish.com.",
    "job_type": "Not specified",
    "remote_status": "Remote",
    "experience_level": "1+ years",
    "required_skills": [
      "Python",
      "SQL",
      "English",
      "Data Analysis",
      "Data Visualization",
      "Marketing Ecosystem and Measurement Framework knowledge",
      "Media Measurement Methodologies (media mix modeling, incrementality analysis, attribution modeling)",
      "Machine Learning concepts",
      "Collaborative mindset",
      "Problem-solving skills"
    ],
    "education": "Not specified",
    "technologies": [
      "Python",
      "SQL",
      "Tableau",
      "Looker",
      "Matplotlib",
      "Amazon Marketing Cloud",
      "Google ADH",
      "Campaign Manager",
      "Meta",
      "Google Analytics",
      "Media Mix Models",
      "Geo-based Incrementally Experiments",
      "Causal Impact Studies",
      "Incrementality Testing",
      "Data Clean Rooms"
    ],
    "job_responsibilities": "Create impact within Investment Analytics and assist with Paid Media data applications. Lead complex data science solutions, guide multi-capability presentations, and own advanced measurement and testing for clients. Analyze data to discover hidden trends and deliver actionable recommendations. Explain and promote data science methodologies such as Media Mix Models, Geo-based Incrementally Experiments, Causal Impact Studies, and other statistically sound testing approaches to enhance campaign performance. Develop and implement Marketing Mix Models. Work with platform partners to grow the suite of mathematical techniques for Incrementally Testing, Media Mix Modeling, and Data Clean Rooms using open-source and in-house code. Document analytics projects for replication and scalability. Seek and implement solutions to improve and automate processes."
  },
  {
    "position": "Data Scientist",
    "company": "HCLTech",
    "location": "Bangalore, Chennai, Noida, Hyderabad, Pune",
    "date": "2025-07-17",
    "salary": "Not specified",
    "jobUrl": "https://in.linkedin.com/jobs/view/data-scientist-at-hcltech-4266957142?position=6&pageNum=0&refId=BYLSx0BZGtZh2eH4pz2Fdg%3D%3D&trackingId=uPF4JkPoxyzW6RkHlSAKQw%3D%3D",
    "companyLogo": "https://media.licdn.com/dms/image/v2/C4D0BAQF-RIoeeMTMKQ/company-logo_100_100/company-logo_100_100/0/1664197008220/hcltech_logo?e=2147483647&v=beta&t=xcyEJUPhrb87C_rsxS_BX3_2bZJF40KfbSVTJWSFdkU",
    "agoTime": "2 days ago",
    "metadata": {
      "keyword": "AI Accelerator Engineer",
      "location": "Bangalore",
      "experienceLevel": "Chief Technology Officer",
      "remoteFilter": "hybrid"
    },
    "job_description": "Hiring for Data Scientist- AI Developer in HCLTechInterested candidate share your resume at selvakumari.b@hcltech.com with below formatEXP- 5 to 15YearsLocation- Bangalore, Chennai, Noida, Hyderabad, PuneName: Contact Number:Email ID:Current Location:Preferred Location:Total Experience:Relevant Experience:Current Organization:Current CTC:Expected CTC:Notice Period:Are you available for Interview this Weekend ?*Required Skills:*- *Technical Skills*: Proficiency in programming languages like Python, R, , and experience with machine learning algorithms, Deep learning-Strong foundation in statistics, mathematics,- *Communication*: Ability to communicate complex concepts clearly and effectively to stakeholders, and tailor messages for business applicability.- *Leadership*: Strong leadership and management skills, with the ability to build relationships with stakeholders and advocate for data-driven decision-making.",
    "job_type": "Not specified",
    "remote_status": "Not specified",
    "experience_level": "5 to 15 Years",
    "required_skills": [
      "Python",
      "R",
      "machine learning algorithms",
      "Deep learning",
      "statistics",
      "mathematics",
      "communication",
      "leadership",
      "management"
    ],
    "education": "Not specified",
    "technologies": [
      "Python",
      "R",
      "machine learning algorithms",
      "Deep learning"
    ],
    "job_responsibilities": "Not specified"
  },
  {
    "position": "Python Developer (SDE3/PE)",
    "company": "Kotak Mahindra Bank",
    "location": "Bengaluru, Karnataka, India",
    "date": "2025-07-15",
    "salary": "Not specified",
    "jobUrl": "https://in.linkedin.com/jobs/view/python-developer-sde3-pe-at-kotak-mahindra-bank-4266615857?position=7&pageNum=0&refId=BYLSx0BZGtZh2eH4pz2Fdg%3D%3D&trackingId=83rZ23i8GIjfdBvxarxSBg%3D%3D",
    "companyLogo": "https://media.licdn.com/dms/image/v2/C510BAQF-GW7Nv4Reuw/company-logo_100_100/company-logo_100_100/0/1630581793286/kotak_mahindra_bank_logo?e=2147483647&v=beta&t=aGxSC4UtWM1c_BVQBZG9Kp8pXQbtKS3g-bVRXwyBcMw",
    "agoTime": "4 days ago",
    "metadata": {
      "keyword": "AI Accelerator Engineer",
      "location": "Bangalore",
      "experienceLevel": "Chief Technology Officer",
      "remoteFilter": "hybrid"
    },
    "job_description": "About the Role:We are looking for a passionate and experienced Sr. Python Developer to join our team and play key role in building the next generation of risk systems. You will be responsible for the design, development, and implementation of data intensive quantitive solutions that meet the demanding requirements of Risk applications.Responsibilities:Design, develop, and test data intensive, quantitive solutions.Prepare technical documentation and mentor team members.Collaborate with Risk, Tech, and other teams to understand business requirements and translate them into technical solutions.Work with the team to provide technical guidance, review code etc. Good knowledge in test case automation.Work with Principal Engineer for ARB review, Infra review etc.Stay up-to-date with the latest technologies and trends.Qualifications:Minimum 6-12 years of experience in design and development of large-scale systems.Hands on experience on large scale system development in Python, Django, FastAPI.Prior experience on design and architecture on AWS services.Hands on experience on large scale system development.Strong understanding of design patterns, Python, OpenAPI specifications and API integrations.Excellent problem-solving and analytical skills.Strong communication and collaboration skills.Ability to work independently and as part of a team.Bonus Points:Experience with scalable data intensive financial systems.Awareness on Risk domain.Knowledge of cloud-based deployment and containerization technologies.Experience with Agile development methodologies.",
    "job_type": "Not specified",
    "remote_status": "Not specified",
    "experience_level": "6-12 years",
    "required_skills": [
      "Python",
      "Django",
      "FastAPI",
      "AWS services",
      "OpenAPI specifications",
      "API integrations",
      "design patterns",
      "test case automation"
    ],
    "education": "Not specified",
    "technologies": [
      "Python",
      "Django",
      "FastAPI",
      "AWS",
      "OpenAPI",
      "cloud-based deployment",
      "containerization"
    ],
    "job_responsibilities": "Design, develop, test, and implement data intensive quantitative solutions; prepare technical documentation; mentor team members; collaborate with Risk, Tech, and other teams to understand business requirements and translate them into technical solutions; provide technical guidance and review code; work with Principal Engineer for ARB and Infra reviews; stay up-to-date with the latest technologies and trends."
  },
  {
    "position": "AI Engineer",
    "company": "Swirl\u00ae",
    "location": "Bengaluru, Karnataka, India",
    "date": "2025-07-17",
    "salary": "Top-of-market cash + meaningful founding equity",
    "jobUrl": "https://in.linkedin.com/jobs/view/ai-engineer-at-swirl%C2%AE-4266996452?position=8&pageNum=0&refId=BYLSx0BZGtZh2eH4pz2Fdg%3D%3D&trackingId=QQMb6Ti4nu1HCN4zVSsLRA%3D%3D",
    "companyLogo": "https://media.licdn.com/dms/image/v2/D4D0BAQHSHQ9LKfraAw/company-logo_100_100/company-logo_100_100/0/1738924403408/swirl_live_app_logo?e=2147483647&v=beta&t=9qqDl1sLcpytJc4iMBes7-iygyouhKwOp7Y_IEvV9wc",
    "agoTime": "1 day ago",
    "metadata": {
      "keyword": "AI Accelerator Engineer",
      "location": "Bangalore",
      "experienceLevel": "Chief Technology Officer",
      "remoteFilter": "hybrid"
    },
    "job_description": "Swirl AI turns every product page into a human-like sales conversation, blending LLMs, video understanding, real-time retrieval and agent orchestration. We\u2019ve rocketed from 0 \u2192 Eight Figures of ARR in few months, and demand is outpacing our 7-person tech team. So, we need one extraordinary engineer to own the core of our platform and push it to Silicon Valley scale.What you\u2019ll doFirst 90 days\u2022 Deep-dive into our multimodal stack (OpenAI-/Claude-based LLMs, custom SLMs, Azure Video Indexer, Pinecone/RAG, LangGraph)\u2022 Ship v2 of our SKU-specific \u201cvideo-+-text\u201d agent (latency < 500 ms, zero hallucinations).\u2022 Productionize auto-evaluation + guardrails (sentiment, brand safety)\u2022 Stand up voice & XR modalities and experiment with on-device inference. 6-12 months\u2022 Real-time GEO optimisation\u2022 Lead design of our \u201cagent marketplace\u201d: plug-and-play warranty, finance-offer & upsell agents.\u2022 Drive infra hardening to handle 10 M+ interactions / month across multiple Fortune-500 sites.Long term\u2022 Build and mentor an elite AI / ML/systems team.\u2022 Architect the path to: self-serve onboarding, global content network.You might be a fit if youHave 1-5+ yrs building production systems at scaleShipped deep-learning products end-to-end: data pipeline \u279c model training/fine-tuning \u279c safety/guardrails \u279c Serving (K8s, CUDA, Triton, Ray, or similar).Hands-on with multimodal (video, speech, vision) and agentic/RAG architectures.Fluent in Python/Typescript/Go; can debug distributed systems at 2 a.m. and still think product.Thrive in zero-to-one chaos: sketch, hack, iterate, talk to customers, then rewrite for scale.Believe ownership > titles, data-driven rigor > ego, and shipping weekly > polishing forever.What success looks likep50 latency < 500 ms for a multimodal query across 100k videos & 10M documents.Swirl AI becomes the reference \u201cAI Sales Agent\u201d demo in every Fortune-100 board deck.We out-innovate incumbents (Salesforce, Adobe, Shopify) by shipping features 4\u00d7 faster with a team 10\u00d7 leaner.Comp, stage & perksTop-of-market cash + meaningful founding equity (we\u2019re an early-stage, venture-backed rocket).Choose your rig: M-series MacBook + 4k monitor or Linux workstation with RTX 6000.Remote-first (US / EU / India time overlap) with quarterly off-sites in Dubai, SF & Bangalore.Visa support, health + mental-wellness stipend, conference budget, unlimited books.Report directly to Kaizad Hansotia (Founder/CEO) & Akshil Shah (CTO) and shape the product that\u2019s already trusted by BYD, Toyota, LG & Lennox.How to applySend GitHub/LinkedIn + 2-3 sentences on the toughest system you\u2019ve built to careers@goswirl.ai. Side-projects, papers, or a Loom walk-through of your favourite model-ops trick = huge plus.We move fast: expect a 48-hr reply \u2192 1 technical deep-dive \u2192 paid take-home sprint \u2192 offer.Join us to make product pages talk, show & sell \u2014 at human level, globally.",
    "job_type": "Not specified",
    "remote_status": "Remote-first",
    "experience_level": "1-5+ yrs",
    "required_skills": [
      "Python",
      "Typescript",
      "Go",
      "Building production systems at scale",
      "Deep-learning product shipping (end-to-end)",
      "Multimodal architectures (video, speech, vision)",
      "Agentic architectures",
      "RAG architectures",
      "Debugging distributed systems",
      "Data pipeline",
      "Model training/fine-tuning",
      "Safety/Guardrails",
      "Serving"
    ],
    "education": "Not specified",
    "technologies": [
      "Python",
      "Typescript",
      "Go",
      "LLMs (OpenAI, Claude)",
      "SLMs",
      "Azure Video Indexer",
      "Pinecone",
      "RAG",
      "LangGraph",
      "K8s",
      "CUDA",
      "Triton",
      "Ray"
    ],
    "job_responsibilities": [
      "Own the core of the platform and push it to Silicon Valley scale",
      "Deep-dive into multimodal stack",
      "Ship v2 of SKU-specific \u201cvideo-+-text\u201d agent",
      "Productionize auto-evaluation + guardrails (sentiment, brand safety)",
      "Stand up voice & XR modalities and experiment with on-device inference",
      "Lead design of \u201cagent marketplace\u201d",
      "Drive infra hardening to handle 10 M+ interactions / month",
      "Build and mentor an elite AI / ML/systems team",
      "Architect the path to self-serve onboarding and global content network"
    ]
  },
  {
    "position": "Data Scientist",
    "company": "Recro",
    "location": "Bengaluru, Karnataka, India",
    "date": "2025-07-16",
    "salary": "Not specified",
    "jobUrl": "https://in.linkedin.com/jobs/view/data-scientist-at-recro-4267672713?position=9&pageNum=0&refId=BYLSx0BZGtZh2eH4pz2Fdg%3D%3D&trackingId=fPmUZ%2BBcxGJNa0eF%2FnalOw%3D%3D",
    "companyLogo": "https://media.licdn.com/dms/image/v2/D560BAQH7GYOGBCj8Qg/company-logo_100_100/company-logo_100_100/0/1728907260215/recro_io_logo?e=2147483647&v=beta&t=898rSyj182aC0vqi5cZqbWQQIDumt_WpercCJsH_-TY",
    "agoTime": "3 days ago",
    "metadata": {
      "keyword": "AI Accelerator Engineer",
      "location": "Bangalore",
      "experienceLevel": "Chief Technology Officer",
      "remoteFilter": "hybrid"
    },
    "job_description": "Exp: 2+ yearsJob ResponsibilitiesUndertake data collection, preprocessing, and analysisBuild models to address business problemsPresent information using data visualization techniquesPropose solutions and strategies to business challengesCollaborate with engineering and product development teamsDevelop machine learning algorithmsConduct data-driven experiments to drive business decisionsRequired SkillsStrong experience in machine learning and operations research with team leadership capabilitiesProficiency in R, SQL, and PythonHands-on experience with business intelligence tools (e.g., Tableau, Power BI)Strong math skills (e.g., statistics, algebra)Analytical mindset and solid business acumenExcellent communication and presentation skillsPreferred Algorithms and Use CasesText Analytics: Experience with Natural Language Processing (NLP) algorithms for sentiment analysis, text classification, named entity recognitionPredictive Modeling: Familiarity with various models including regression, classification, and time series forecasting methods such as ARIMA, SARIMA, and Prophet",
    "job_type": "Not specified",
    "remote_status": "Not specified",
    "experience_level": "2+ years",
    "required_skills": [
      "machine learning",
      "operations research",
      "team leadership capabilities",
      "R",
      "SQL",
      "Python",
      "business intelligence tools",
      "Tableau",
      "Power BI",
      "math skills",
      "statistics",
      "algebra",
      "Analytical mindset",
      "business acumen",
      "communication",
      "presentation skills",
      "Text Analytics",
      "Natural Language Processing (NLP)",
      "sentiment analysis",
      "text classification",
      "named entity recognition",
      "Predictive Modeling",
      "regression",
      "classification",
      "time series forecasting",
      "ARIMA",
      "SARIMA",
      "Prophet"
    ],
    "education": "Not specified",
    "technologies": [
      "R",
      "SQL",
      "Python",
      "Tableau",
      "Power BI",
      "ARIMA",
      "SARIMA",
      "Prophet",
      "Natural Language Processing (NLP)"
    ],
    "job_responsibilities": "Undertake data collection, preprocessing, and analysis; Build models to address business problems; Present information using data visualization techniques; Propose solutions and strategies to business challenges; Collaborate with engineering and product development teams; Develop machine learning algorithms; Conduct data-driven experiments to drive business decisions"
  }
]